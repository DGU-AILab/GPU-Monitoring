#!/bin/bash

# í•¨ìˆ˜: GPU ì‚¬ìš©ëŸ‰ ë¡œê¹…
# Usage: log_gpu_usage "<label>" "<command to run>"
log_gpu_usage() {
    local label="$1"
    local cmd="$2"
    echo "   ðŸ”§ $label usage:" >> "$LOG_FILE"
    local output
    while IFS= read -r line; do
        local name=$(echo "$line" | cut -d',' -f1 | xargs)
        local util=$(echo "$line" | cut -d',' -f2 | xargs)
        echo "     - $name: ${util}% usage" >> "$LOG_FILE"
    done < <(eval "$cmd")
}

# í•¨ìˆ˜: ìŠ¬ëž™ ì•Œë¦¼ ì „ì†¡
# Usage: alert_slack "<text message>"
alert_slack() {
    local msg="$1"
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"$msg\"}" \
        https://hooks.slack.com/services/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
}

# í•¨ìˆ˜: ëª¨ë“  ì»¨í…Œì´ë„ˆ ë˜ëŠ” íŠ¹ì • ì»¨í…Œì´ë„ˆì— ì ‘ì†í•œ ì‚¬ìš©ìžì—ê²Œ ë©”ì‹œì§€ ë¸Œë¡œë“œìºìŠ¤íŠ¸
broadcast_shutdown_message() {
    local msg="$1"
    local target_container="$2"

    if [ -z "$target_container" ]; then
        for container in $(docker ps -q); do
            docker exec "$container" bash -c "echo '$msg' | wall 2>/dev/null"
        done
    else
        docker exec "$target_container" bash -c "echo '$msg' | wall 2>/dev/null"
    fi
}

SERVER_NAME="FARM9"

LOG_FILE="gpu_container_usage.log"
TIMESTAMP=$(date "+%Y-%m-%d %H:%M:%S")


echo "==================== [$TIMESTAMP] GPU Container Check ====================" >> "$LOG_FILE"

# í˜¸ìŠ¤íŠ¸ì˜ GPU ìƒíƒœ ë¨¼ì € í™•ì¸
echo "â–¶ï¸ Host GPU Status:" >> "$LOG_FILE"
HOST_GPU_INFO_CMD="nvidia-smi --query-gpu=name,utilization.gpu --format=csv,noheader,nounits 2>&1"
HOST_GPU_STATUS=$?
if [ $HOST_GPU_STATUS -eq 0 ]; then
    echo "   âœ… Host GPU access: YES" >> "$LOG_FILE"
    log_gpu_usage "Host GPU" "$HOST_GPU_INFO_CMD"
else
    alert_slack "[ALERT] Host GPU access failed on server: $SERVER_NAME"
    echo "   âŒ Host GPU access: NO" >> "$LOG_FILE"
    echo "      â†ª Error: $(eval "$HOST_GPU_INFO_CMD")" >> "$LOG_FILE"
    echo "   ðŸ” Rebooting host server due to GPU access failure..." >> "$LOG_FILE"

    broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ê°€ 10ë¶„ í›„ ìž¬ë¶€íŒ…ë©ë‹ˆë‹¤. ì €ìž¥í•˜ì§€ ì•Šì€ ìž‘ì—…ì€ ë¯¸ë¦¬ ë°±ì—…í•´ì£¼ì„¸ìš”."
    sleep 300
    broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ê°€ 5ë¶„ í›„ ìž¬ë¶€íŒ…ë©ë‹ˆë‹¤."
    sleep 240

    broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ê°€ 1ë¶„ í›„ ìž¬ë¶€íŒ…ë©ë‹ˆë‹¤."
    sleep 50

    for i in $(seq 10 -1 1); do
        broadcast_shutdown_message "[ALERT] ì„œë²„ ìž¬ë¶€íŒ…ê¹Œì§€ ${i}ì´ˆ ë‚¨ì•˜ìŠµë‹ˆë‹¤."
        sleep 1
    done

    broadcast_shutdown_message "[ALERT] ì´ì œ ${SERVER_NAME} ì„œë²„ê°€ ìž¬ë¶€íŒ…ë©ë‹ˆë‹¤."
    sudo reboot
fi

echo "" >> "$LOG_FILE"

# ëª¨ë“  ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ ìˆœíšŒ
docker ps --format "{{.ID}} {{.Names}} {{.Image}}" | while read -r CONTAINER_ID CONTAINER_NAME CONTAINER_IMAGE; do
    echo "â–¶ï¸ Container: $CONTAINER_NAME ($CONTAINER_ID) [$CONTAINER_IMAGE]" >> "$LOG_FILE"

    echo "   ðŸ” Checking container runtime..." >> "$LOG_FILE"
    RUNTIME=$(docker inspect --format='{{.HostConfig.Runtime}}' "$CONTAINER_ID")
    echo "   â†ª Runtime: $RUNTIME" >> "$LOG_FILE"

    echo "   ðŸ” Checking NVIDIA device files in container..." >> "$LOG_FILE"
    DEVICE_FILES=$(docker exec "$CONTAINER_ID" ls /dev/nvidia* 2>&1)
    echo "   â†ª Device files: $DEVICE_FILES" >> "$LOG_FILE"

    # 22ë²ˆ í¬íŠ¸ ë§¤í•‘ëœ í˜¸ìŠ¤íŠ¸ í¬íŠ¸ í™•ì¸
    HOST_PORT=$(docker port "$CONTAINER_ID" 22 2>/dev/null | awk -F: '{print $2}' | tr -d ' ')
    [ -z "$HOST_PORT" ] && HOST_PORT="(not exposed)"
    echo "   â†ª SSH (port 22) mapped to host: $HOST_PORT" >> "$LOG_FILE"

    # ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ nvidia-smi ì‹¤í–‰ ì‹œë„
    OUTPUT=$(docker exec "$CONTAINER_ID" nvidia-smi --query-gpu=name,utilization.gpu --format=csv,noheader,nounits 2>&1)
    STATUS=$?

    if [ $STATUS -eq 0 ]; then
        echo "   âœ… GPU access: YES" >> "$LOG_FILE"
        log_gpu_usage "Container GPU" "docker exec \"$CONTAINER_ID\" nvidia-smi --query-gpu=name,utilization.gpu --format=csv,noheader,nounits"

    else
        echo "   âŒ GPU access: NO (initial)" >> "$LOG_FILE"
        echo "      â†ª Error: $OUTPUT" >> "$LOG_FILE"

        # ì»¤ë„ ëª¨ë“ˆ ë¡œë”© ìƒíƒœ í™•ì¸
        echo "   ðŸ” Checking loaded NVIDIA kernel modules..." >> "$LOG_FILE"
        lsmod | grep -E 'nvidia(_uvm)?' >> "$LOG_FILE"

        echo "   ðŸ”„ Attempting to reload nvidia modules on host..." >> "$LOG_FILE"
        sudo rmmod nvidia_uvm nvidia_modeset nvidia_drm nvidia 2>/dev/null
        sudo modprobe nvidia && sudo modprobe nvidia_uvm

        sleep 2  # ëª¨ë“ˆ ìž¬ë¡œë“œ í›„ ì•ˆì •í™” ëŒ€ê¸°
        echo "   ðŸ” Verifying NVIDIA modules loaded after reload..." >> "$LOG_FILE"
        if lsmod | grep -q -E 'nvidia(_uvm)?'; then
            echo "   âœ… NVIDIA modules are loaded" >> "$LOG_FILE"
        else
            echo "   âŒ NVIDIA modules failed to load" >> "$LOG_FILE"
        fi

        OUTPUT2=$(docker exec "$CONTAINER_ID" nvidia-smi --query-gpu=name,utilization.gpu --format=csv,noheader,nounits 2>&1)
        STATUS2=$?

        if [ $STATUS2 -eq 0 ]; then
            echo "   âœ… GPU access: YES (after module reload)" >> "$LOG_FILE"
            log_gpu_usage "Container GPU" "docker exec \"$CONTAINER_ID\" nvidia-smi --query-gpu=name,utilization.gpu --format=csv,noheader,nounits"
        else
            echo "   âŒ GPU access: STILL FAILING after module reload" >> "$LOG_FILE"
            alert_slack "[ALERT] GPU access still failing after reload in container: $CONTAINER_NAME ($CONTAINER_ID)"
            echo "   ðŸ” Restarting container $CONTAINER_NAME ($CONTAINER_ID) on $SERVER_NAME due to persistent GPU failure..." >> "$LOG_FILE"
            broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ì˜ ì»¨í…Œì´ë„ˆ $CONTAINER_NAME ê°€ 10ë¶„ í›„ ìž¬ì‹œìž‘ë©ë‹ˆë‹¤. ì €ìž¥í•˜ì§€ ì•Šì€ ìž‘ì—…ì€ ë¯¸ë¦¬ ë°±ì—…í•´ì£¼ì„¸ìš”." "$CONTAINER_ID"
            sleep 300
            broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ì˜ ì»¨í…Œì´ë„ˆ $CONTAINER_NAME ê°€ 5ë¶„ í›„ ìž¬ì‹œìž‘ë©ë‹ˆë‹¤." "$CONTAINER_ID"
            sleep 240
            broadcast_shutdown_message "[ALERT] ${SERVER_NAME} ì„œë²„ì˜ ì»¨í…Œì´ë„ˆ $CONTAINER_NAME ê°€ 1ë¶„ í›„ ìž¬ì‹œìž‘ë©ë‹ˆë‹¤." "$CONTAINER_ID"
            sleep 50
            for i in $(seq 10 -1 1); do
                broadcast_shutdown_message "[ALERT] ${CONTAINER_NAME} ì»¨í…Œì´ë„ˆ ìž¬ì‹œìž‘ê¹Œì§€ ${i}ì´ˆ ë‚¨ì•˜ìŠµë‹ˆë‹¤." "$CONTAINER_ID"
                sleep 1
            done
            broadcast_shutdown_message "[ALERT] ${CONTAINER_NAME} ì»¨í…Œì´ë„ˆë¥¼ ì´ì œ ìž¬ì‹œìž‘í•©ë‹ˆë‹¤." "$CONTAINER_ID"
            docker restart "$CONTAINER_ID" >> "$LOG_FILE" 2>&1
            echo "      â†ª Error: $OUTPUT2" >> "$LOG_FILE"
            alert_slack "[ALERT] Restarted container $CONTAINER_NAME ($CONTAINER_ID) on $SERVER_NAME due to persistent GPU failure."
        fi
    fi

    echo "" >> "$LOG_FILE"
done

echo "" >> "$LOG_FILE"